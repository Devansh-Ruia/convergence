from typing import List, Dict, Any

TEMPLATES = {
    "default": """## ğŸ” Convergence Code Review

**PR:** [{pr_title}]({pr_url})
**Analyzed by:** {agents_count} agents in {duration_s:.1f}s

---

{findings_content}

---

### ğŸ“Š Summary

| Severity | Count |
|----------|-------|
| ğŸš¨ Critical/High | {critical_count} |
| âš ï¸ Medium | {medium_count} |
| ğŸ’¡ Low/Info | {low_count} |
| **Total** | **{total_count}** |

---

<sub>ğŸ¤– Reviewed by **Convergence** â€¢ Agents: [{agents}] â€¢ {duration_s:.1f}s</sub>""",
    
    "minimal": """## ğŸ” Convergence Review

**PR:** [{pr_title}]({pr_url}) â€¢ {agents_count} agents â€¢ {duration_s:.1f}s

{critical_findings}

{medium_findings}

{low_findings}

**Summary:** {total_count} findings ({critical_count} critical)

---
*Reviewed by Convergence*""",
    
    "detailed": """## ğŸ” Convergence Code Review - Detailed Analysis

**PR:** [{pr_title}]({pr_url})
**Analyzed by:** {agents_count} agents in {duration_s:.1f}s
**Review Date:** {timestamp}

---

{findings_content}

---

## ğŸ“Š Detailed Statistics

### Severity Breakdown
- **Critical (ğŸ”´):** {critical_count} findings
- **High (ğŸŸ ):** {high_count} findings  
- **Medium (ğŸŸ¡):** {medium_count} findings
- **Low (ğŸ”µ):** {low_count} findings
- **Info (âšª):** {info_count} findings

### Agent Contributions
{agent_contributions}

### Cross-References
{cross_references}

---

### Performance Metrics
- **Total Review Time:** {duration_s:.1f}s
- **Average Agent Latency:** {avg_latency_ms:.0f}ms
- **Findings per Agent:** {findings_per_agent:.1f}

---

<sub>ğŸ¤– Detailed review by **Convergence** â€¢ Agents: [{agents}] â€¢ {timestamp}</sub>""",
    
    "checklist": """## ğŸ” Convergence Review Checklist

**PR:** [{pr_title}]({pr_url})
**Reviewers:** {agents_count} agents â€¢ {duration_s:.1f}s

---

### âœ… Must Fix (Critical/High)
{checklist_critical}

### âš ï¸ Should Fix (Medium)  
{checklist_medium}

### ğŸ’¡ Consider (Low/Info)
{checklist_low}

---

### ğŸ“Š Summary
- **Total Issues:** {total_count}
- **Critical:** {critical_count} | **Medium:** {medium_count} | **Low:** {low_count}

---

*Generated by Convergence â€¢ {agents} agents â€¢ {duration_s:.1f}s*"""
}


def synthesize_with_template(
    findings: List[Dict[str, Any]], 
    pr_title: str,
    pr_url: str,
    agents_completed: List[str],
    duration_ms: int,
    template_name: str = "default",
    cross_refs: List[Dict[str, Any]] = None,
    agent_latencies: Dict[str, int] = None
) -> str:
    """
    Generate review using specified template.
    """
    if template_name not in TEMPLATES:
        raise ValueError(f"Unknown template: {template_name}. Available: {list(TEMPLATES.keys())}")
    
    template = TEMPLATES[template_name]
    
    # Calculate statistics
    critical = [f for f in findings if f.get("severity", 0) >= 5]
    high = [f for f in findings if f.get("severity", 0) == 4]
    medium = [f for f in findings if 2 <= f.get("severity", 0) <= 3]
    low = [f for f in findings if f.get("severity", 0) == 1]
    info = [f for f in findings if f.get("severity", 0) == 0]
    
    critical_count = len(critical) + len(high)
    medium_count = len(medium)
    low_count = len(low) + len(info)
    total_count = len(findings)
    
    # Format findings content based on template
    if template_name == "minimal":
        findings_content = _format_minimal_findings(critical, high, medium, low, info)
    elif template_name == "detailed":
        findings_content = _format_detailed_findings(findings, critical, high, medium, low, info)
    elif template_name == "checklist":
        findings_content = _format_checklist_findings(critical, high, medium, low, info)
    else:
        findings_content = _format_default_findings(findings, critical, high, medium, low, info)
    
    # Prepare template variables
    template_vars = {
        "pr_title": pr_title,
        "pr_url": pr_url,
        "agents_count": len(agents_completed),
        "agents": ", ".join(a.title() for a in agents_completed),
        "duration_s": duration_ms / 1000,
        "duration_ms": duration_ms,
        "critical_count": critical_count,
        "high_count": len(high),
        "medium_count": medium_count,
        "low_count": low_count,
        "info_count": len(info),
        "total_count": total_count,
        "findings_content": findings_content,
        "timestamp": _format_timestamp(),
        "avg_latency_ms": sum(agent_latencies.values()) / len(agent_latencies) if agent_latencies else 0,
        "findings_per_agent": total_count / len(agents_completed) if agents_completed else 0
    }
    
    # Add template-specific variables
    if template_name == "minimal":
        template_vars.update({
            "critical_findings": _format_minimal_section(critical + high, "ğŸš¨ Critical"),
            "medium_findings": _format_minimal_section(medium, "âš ï¸ Medium"),
            "low_findings": _format_minimal_section(low + info, "ğŸ’¡ Low")
        })
    elif template_name == "detailed":
        template_vars.update({
            "agent_contributions": _format_agent_contributions(findings, agents_completed),
            "cross_references": _format_cross_references(cross_refs or [])
        })
    elif template_name == "checklist":
        template_vars.update({
            "checklist_critical": _format_checklist_section(critical + high),
            "checklist_medium": _format_checklist_section(medium),
            "checklist_low": _format_checklist_section(low + info)
        })
    
    return template.format(**template_vars)


def _format_default_findings(findings, critical, high, medium, low, info):
    """Format findings for default template."""
    from app.orchestrator.convergence import format_finding_markdown
    
    sections = []
    
    if critical or high:
        sections.append(f"### ğŸš¨ Critical Issues ({len(critical) + len(high)})")
        sections.append("")
        for f in critical + high:
            sections.extend(format_finding_markdown(f))
    
    if medium:
        sections.append(f"### âš ï¸ Recommendations ({len(medium)})")
        sections.append("")
        for f in medium:
            sections.extend(format_finding_markdown(f))
    
    if low or info:
        sections.append(f"### ğŸ’¡ Suggestions ({len(low) + len(info)})")
        sections.append("")
        for f in low + info:
            sections.extend(format_finding_markdown(f))
    
    if not findings:
        sections.extend([
            "### âœ… No Issues Found",
            "",
            "This PR looks good! No significant issues detected by our analysis.",
            ""
        ])
    
    return "\n".join(sections)


def _format_minimal_findings(critical, high, medium, low, info):
    """Format findings for minimal template."""
    return ""  # Handled by separate sections in minimal template


def _format_minimal_section(findings, title):
    """Format a section for minimal template."""
    if not findings:
        return f"**{title}:** None âœ…\n"
    
    lines = [f"**{title}:**"]
    for f in findings:
        file_path = f.get("file_path", "unknown")
        line_start = f.get("line_start", 0)
        title_text = f.get("title", "Issue")
        severity = f.get("severity", 3)
        
        emoji = "ğŸ”´" if severity >= 4 else "ğŸŸ¡" if severity >= 2 else "âšª"
        lines.append(f"- {emoji} `{file_path}:{line_start}` {title_text}")
    
    return "\n".join(lines) + "\n"


def _format_detailed_findings(findings, critical, high, medium, low, info):
    """Format findings for detailed template."""
    return _format_default_findings(findings, critical, high, medium, low, info)


def _format_checklist_findings(critical, high, medium, low, info):
    """Format findings for checklist template."""
    return ""  # Handled by separate sections in checklist template


def _format_checklist_section(findings):
    """Format findings as GitHub task list."""
    if not findings:
        return "- No items âœ…\n"
    
    lines = []
    for f in findings:
        file_path = f.get("file_path", "unknown")
        line_start = f.get("line_start", 0)
        title_text = f.get("title", "Issue")
        
        lines.append(f"- [ ] `{file_path}:{line_start}` {title_text}")
    
    return "\n".join(lines) + "\n"


def _format_agent_contributions(findings, agents_completed):
    """Format agent contribution statistics."""
    from collections import defaultdict
    
    agent_counts = defaultdict(int)
    for f in findings:
        sources = f.get("_sources", [f.get("_source", "unknown")])
        for source in sources:
            agent_counts[source] += 1
    
    lines = ["**Findings by Agent:**"]
    for agent in agents_completed:
        count = agent_counts.get(agent, 0)
        lines.append(f"- **{agent.title()}:** {count} findings")
    
    return "\n".join(lines)


def _format_cross_references(cross_refs):
    """Format cross-reference summary."""
    if not cross_refs:
        return "**Cross-References:** None"
    
    lines = [f"**Cross-References:** {len(cross_refs)} agent interactions"]
    
    # Count by relationship type
    from collections import Counter
    rel_counts = Counter(cr["relationship"] for cr in cross_refs)
    
    for rel_type, count in rel_counts.items():
        lines.append(f"- **{rel_type.title()}:** {count}")
    
    return "\n".join(lines)


def _format_timestamp():
    """Format current timestamp."""
    from datetime import datetime
    return datetime.utcnow().strftime("%Y-%m-%d %H:%M UTC")
